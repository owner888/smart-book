<?php
/**
 * HTTP/WebSocket è¯·æ±‚å¤„ç†å‡½æ•°
 */

use Workerman\Connection\TcpConnection;
use Workerman\Protocols\Http\Request;
use Workerman\Protocols\Http\Response;
use SmartBook\AI\AIService;
use SmartBook\AI\TokenCounter;
use SmartBook\Cache\CacheService;
use SmartBook\RAG\EmbeddingClient;
use SmartBook\RAG\VectorStore;

// ===================================
// HTTP ä¸»å…¥å£
// ===================================

function handleHttpRequest(TcpConnection $connection, Request $request): void
{
    $path = $request->path();
    $method = $request->method();
    
    $jsonHeaders = [
        'Content-Type' => 'application/json; charset=utf-8',
        'Access-Control-Allow-Origin' => '*',
        'Access-Control-Allow-Methods' => 'GET, POST, OPTIONS',
        'Access-Control-Allow-Headers' => 'Content-Type',
    ];
    
    if ($method === 'OPTIONS') {
        $connection->send(new Response(200, $jsonHeaders, ''));
        return;
    }
    
    try {
        // é¦–é¡µ
        if ($path === '/' || $path === '/index.html') {
            $indexHtmlPath = dirname(__DIR__, 2) . '/index.html';
            if (file_exists($indexHtmlPath)) {
                $connection->send(new Response(200, ['Content-Type' => 'text/html; charset=utf-8'], file_get_contents($indexHtmlPath)));
                return;
            }
        }
        
        // pages ç›®å½•ä¸‹çš„é¡µé¢
        if (str_starts_with($path, '/pages/')) {
            $pagePath = dirname(__DIR__, 2) . $path;
            if (file_exists($pagePath)) {
                $connection->send(new Response(200, ['Content-Type' => 'text/html; charset=utf-8'], file_get_contents($pagePath)));
                return;
            }
        }
        
        // é™æ€æ–‡ä»¶
        if (str_starts_with($path, '/static/')) {
            $filePath = dirname(__DIR__, 2) . $path;
            if (file_exists($filePath)) {
                $ext = pathinfo($filePath, PATHINFO_EXTENSION);
                $mimeTypes = [
                    'css' => 'text/css', 
                    'js' => 'application/javascript', 
                    'png' => 'image/png', 
                    'jpg' => 'image/jpeg', 
                    'svg' => 'image/svg+xml',
                    'woff2' => 'font/woff2',
                    'woff' => 'font/woff',
                    'ttf' => 'font/ttf',
                    'eot' => 'application/vnd.ms-fontobject',
                ];
                $connection->send(new Response(200, ['Content-Type' => $mimeTypes[$ext] ?? 'application/octet-stream'], file_get_contents($filePath)));
                return;
            }
        }
        
        // API è·¯ç”±
        $result = match ($path) {
            '/api' => ['status' => 'ok', 'message' => 'Smart Book AI API'],
            '/api/health' => ['status' => 'ok', 'timestamp' => date('Y-m-d H:i:s'), 'redis' => CacheService::isConnected()],
            '/api/models' => handleGetModels(),
            '/api/assistants' => handleGetAssistants(),
            '/api/cache/stats' => handleCacheStats($connection),
            '/api/ask' => handleAskWithCache($connection, $request),
            '/api/chat' => handleChat($request),
            '/api/continue' => handleContinue($request),
            '/api/stream/ask' => handleStreamAskAsync($connection, $request),
            '/api/stream/chat' => handleStreamChat($connection, $request),
            '/api/stream/continue' => handleStreamContinue($connection, $request),
            default => ['error' => 'Not Found', 'path' => $path],
        };
        
        if ($result === null) return;
        
        $statusCode = isset($result['error']) ? 404 : 200;
        $connection->send(new Response($statusCode, $jsonHeaders, json_encode($result, JSON_UNESCAPED_UNICODE | JSON_PRETTY_PRINT)));
        
    } catch (Exception $e) {
        $connection->send(new Response(500, $jsonHeaders, json_encode(['error' => $e->getMessage()], JSON_UNESCAPED_UNICODE)));
    }
}

// ===================================
// WebSocket å¤„ç†
// ===================================

function handleWebSocketMessage(TcpConnection $connection, string $data): void
{
    $request = json_decode($data, true);
    if (!$request) {
        $connection->send(json_encode(['error' => 'Invalid JSON']));
        return;
    }
    
    $action = $request['action'] ?? '';
    
    try {
        match ($action) {
            'ask' => streamAsk($connection, $request),
            'chat' => streamChat($connection, $request),
            'continue' => streamContinue($connection, $request),
            default => $connection->send(json_encode(['error' => 'Unknown action']))
        };
    } catch (Exception $e) {
        $connection->send(json_encode(['error' => $e->getMessage()]));
    }
}

// ===================================
// API å¤„ç†å‡½æ•°
// ===================================

/**
 * è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼ˆä» Gemini API åŠ¨æ€è·å–ï¼‰
 */
function handleGetModels(): array
{
    static $cache = null;
    static $cacheTime = 0;
    
    // ç¼“å­˜ 5 åˆ†é’Ÿ
    if ($cache && (time() - $cacheTime) < 300) {
        return $cache;
    }
    
    $models = [];
    $default = 'gemini-2.5-flash';
    
    // è°ƒç”¨ Gemini Models API
    try {
        $apiKey = GEMINI_API_KEY;
        $url = "https://generativelanguage.googleapis.com/v1beta/models?key={$apiKey}";
        
        $context = stream_context_create([
            'http' => [
                'method' => 'GET',
                'timeout' => 10,
                'header' => "Content-Type: application/json\r\n"
            ]
        ]);
        
        $response = @file_get_contents($url, false, $context);
        
        if ($response) {
            $data = json_decode($response, true);
            
            // å®šä»·è¡¨ï¼ˆUSD per million tokensï¼‰
            $pricing = [
                'gemini-2.5-pro' => ['input' => 2.5, 'output' => 15],
                'gemini-2.5-flash' => ['input' => 0.3, 'output' => 2.5],
                'gemini-2.5-flash-lite' => ['input' => 0.1, 'output' => 0.4],
                'gemini-2.0-flash' => ['input' => 0, 'output' => 0],  // å…è´¹
                'gemini-1.5-pro' => ['input' => 3.5, 'output' => 10.5],
                'gemini-1.5-flash' => ['input' => 0.075, 'output' => 0.3],
            ];
            
            foreach ($data['models'] ?? [] as $model) {
                $modelId = str_replace('models/', '', $model['name']);
                
                // åªæ˜¾ç¤º gemini æ¨¡å‹ï¼Œæ’é™¤ embedding/imagen/text-bison ç­‰
                if (!str_starts_with($modelId, 'gemini')) continue;
                
                // æ’é™¤ preview/exp ç‰ˆæœ¬
                if (str_contains($modelId, 'preview') || str_contains($modelId, 'exp')) continue;
                
                // è®¡ç®—ç›¸å¯¹ä»·æ ¼æ¯”ç‡ (ç›¸å¯¹äº gemini-2.5-pro)
                $basePrice = $pricing['gemini-2.5-pro']['output'];
                $modelPrice = $pricing[$modelId]['output'] ?? 2.5;
                $rate = $modelPrice == 0 ? '0x' : round($modelPrice / $basePrice, 2) . 'x';
                
                $models[] = [
                    'id' => $modelId,
                    'name' => $model['displayName'] ?? $modelId,
                    'provider' => 'google',
                    'rate' => $rate,
                    'description' => $model['description'] ?? '',
                    'context_length' => $model['inputTokenLimit'] ?? 0,
                    'output_limit' => $model['outputTokenLimit'] ?? 0,
                    'default' => $modelId === $default,
                ];
            }
            
            // æŒ‰åç§°æ’åº
            usort($models, fn($a, $b) => strcmp($a['name'], $b['name']));
        }
    } catch (Exception $e) {
        // API è°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤åˆ—è¡¨
    }
    
    // å¦‚æœ API æ²¡è¿”å›æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
    if (empty($models)) {
        $models = [
            ['id' => 'gemini-2.5-flash', 'name' => 'Gemini 2.5 Flash', 'provider' => 'google', 'rate' => '0.33x', 'default' => true],
            ['id' => 'gemini-2.5-pro', 'name' => 'Gemini 2.5 Pro', 'provider' => 'google', 'rate' => '1x'],
        ];
    }
    
    $cache = ['models' => $models, 'default' => $default, 'source' => 'gemini_api'];
    $cacheTime = time();
    
    return $cache;
}

/**
 * è·å–æ‰€æœ‰åŠ©æ‰‹é…ç½®ï¼ˆåŒ…å«ç³»ç»Ÿæç¤ºè¯ï¼‰
 */
function handleGetAssistants(): array
{
    $prompts = $GLOBALS['config']['prompts'];
    $libraryPrompts = $prompts['library'];
    
    // ä» EPUB æ–‡ä»¶è¯»å–ä¹¦ç±å…ƒæ•°æ®
    $bookTitle = 'æœªçŸ¥ä¹¦ç±';
    $bookAuthors = 'æœªçŸ¥ä½œè€…';
    
    if (defined('DEFAULT_BOOK_PATH') && file_exists(DEFAULT_BOOK_PATH)) {
        $metadata = \SmartBook\Parser\EpubParser::extractMetadata(DEFAULT_BOOK_PATH);
        if (!empty($metadata['title'])) {
            $bookTitle = 'ã€Š' . $metadata['title'] . 'ã€‹';
        }
        if (!empty($metadata['authors'])) {
            $bookAuthors = $metadata['authors'];
        }
    }
    
    // æ„å»ºä¹¦ç±åŠ©æ‰‹çš„ç³»ç»Ÿæç¤ºè¯ï¼ˆå®Œå…¨å¯¹é½ Python çš„æ‹¼æ¥é¡ºåºï¼‰
    // 1. book_intro + book_template + separator
    // 2. markdown_instruction
    // 3. unknown_single (å•æœ¬ä¹¦) æˆ– unknown_multiple (å¤šæœ¬ä¹¦)
    // 4. language_instruction
    $bookSystemPrompt = $libraryPrompts['book_intro'] 
        . str_replace(['{which}', '{title}', '{authors}'], ['', $bookTitle, $bookAuthors], $libraryPrompts['book_template']) 
        . $libraryPrompts['separator']
        . $libraryPrompts['markdown_instruction']
        . ($libraryPrompts['unknown_single'] ?? ' If the specified book is unknown to you instead of answering the following questions just say the book is unknown.')
        . ' ' . str_replace('{language}', $prompts['language']['default'], $prompts['language']['instruction']);
    
    return [
        'book' => [
            'name' => 'ä¹¦ç±é—®ç­”åŠ©æ‰‹',
            'avatar' => 'ğŸ“š',
            'color' => '#4caf50',
            'description' => "æˆ‘æ˜¯ä¹¦ç±é—®ç­”åŠ©æ‰‹ï¼Œå¯ä»¥å¸®ä½ åˆ†æ{$bookTitle}çš„å†…å®¹ã€‚ä½ å¯ä»¥é—®æˆ‘å…³äºä¹¦ä¸­äººç‰©ã€æƒ…èŠ‚ã€ä¸»é¢˜ç­‰é—®é¢˜ã€‚",
            'systemPrompt' => $bookSystemPrompt,
            'action' => 'ask',
        ],
        'continue' => [
            'name' => 'ç»­å†™å°è¯´',
            'avatar' => 'âœï¸',
            'color' => '#ff9800',
            'description' => 'æˆ‘æ˜¯å°è¯´ç»­å†™åŠ©æ‰‹ï¼Œæ“…é•¿æ¨¡ä»¿ã€Šè¥¿æ¸¸è®°ã€‹çš„ç« å›ä½“é£æ ¼ç»­å†™æ•…äº‹ã€‚å‘Šè¯‰æˆ‘ä½ æƒ³è¦çš„æƒ…èŠ‚è®¾å®šï¼Œæˆ‘ä¼šä¸ºä½ åˆ›ä½œæ–°ç« èŠ‚ã€‚',
            'systemPrompt' => $prompts['continue']['system'] ?? '',
            'action' => 'continue',
        ],
        'chat' => [
            'name' => 'é€šç”¨èŠå¤©',
            'avatar' => 'ğŸ’¬',
            'color' => '#2196f3',
            'description' => 'æˆ‘æ˜¯é€šç”¨èŠå¤©åŠ©æ‰‹ï¼Œå¯ä»¥å’Œä½ è®¨è®ºä»»ä½•è¯é¢˜ã€‚',
            'systemPrompt' => $prompts['chat']['system'] ?? '',
            'action' => 'chat',
        ],
        'default' => [
            'name' => 'Default Assistant',
            'avatar' => 'â­',
            'color' => '#9c27b0',
            'description' => 'æˆ‘æ˜¯é»˜è®¤åŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„å—ï¼Ÿ',
            'systemPrompt' => 'ä½ æ˜¯ä¸€ä¸ªé€šç”¨ AI åŠ©æ‰‹ï¼Œè¯·å‹å–„åœ°å¸®åŠ©ç”¨æˆ·ã€‚',
            'action' => 'chat',
        ],
    ];
}

function handleChat(Request $request): array
{
    $body = json_decode($request->rawBody(), true) ?? [];
    $messages = $body['messages'] ?? [];
    if (empty($messages)) return ['error' => 'Missing messages'];
    return AIService::chat($messages);
}

function handleContinue(Request $request): array
{
    $body = json_decode($request->rawBody(), true) ?? [];
    return AIService::continueStory($body['prompt'] ?? '');
}

function handleAskWithCache(TcpConnection $connection, Request $request): ?array
{
    $body = json_decode($request->rawBody(), true) ?? [];
    $question = $body['question'] ?? '';
    $topK = $body['top_k'] ?? 8;
    
    if (empty($question)) return ['error' => 'Missing question'];
    
    $cacheKey = CacheService::makeKey('ask', $question . ':' . $topK);
    $jsonHeaders = ['Content-Type' => 'application/json; charset=utf-8', 'Access-Control-Allow-Origin' => '*'];
    
    CacheService::get($cacheKey, function($cached) use ($connection, $question, $topK, $cacheKey, $jsonHeaders) {
        if ($cached) {
            $cached['cached'] = true;
            $connection->send(new Response(200, $jsonHeaders, json_encode($cached, JSON_UNESCAPED_UNICODE)));
            return;
        }
        $result = AIService::askBook($question, $topK);
        $result['cached'] = false;
        CacheService::set($cacheKey, $result);
        $connection->send(new Response(200, $jsonHeaders, json_encode($result, JSON_UNESCAPED_UNICODE)));
    });
    
    return null;
}

function handleCacheStats(TcpConnection $connection): ?array
{
    $jsonHeaders = ['Content-Type' => 'application/json; charset=utf-8', 'Access-Control-Allow-Origin' => '*'];
    CacheService::getStats(fn($stats) => $connection->send(new Response(200, $jsonHeaders, json_encode($stats))));
    return null;
}


// ===================================
// ä¸Šä¸‹æ–‡å‹ç¼©ï¼ˆè‡ªåŠ¨æ‘˜è¦ï¼‰
// ===================================

/**
 * æ£€æŸ¥å¹¶è§¦å‘ä¸Šä¸‹æ–‡æ‘˜è¦
 */
function triggerSummarizationIfNeeded(string $chatId, array $context): void
{
    CacheService::needsSummarization($chatId, function($needsSummary) use ($chatId, $context) {
        if (!$needsSummary) return;
        
        // è·å–å®Œæ•´å†å²ç”¨äºç”Ÿæˆæ‘˜è¦
        CacheService::getChatHistory($chatId, function($history) use ($chatId, $context) {
            if (empty($history)) return;
            
            // æ„å»ºæ‘˜è¦è¯·æ±‚
            $conversationText = "";
            if ($context['summary']) {
                $conversationText .= "ã€ä¹‹å‰çš„æ‘˜è¦ã€‘\n" . $context['summary']['text'] . "\n\nã€æ–°å¯¹è¯ã€‘\n";
            }
            foreach ($history as $msg) {
                $role = $msg['role'] === 'user' ? 'ç”¨æˆ·' : 'AI';
                $conversationText .= "{$role}: {$msg['content']}\n\n";
            }
            
            $summarizePrompt = CacheService::getSummarizePrompt();
            
            // å¼‚æ­¥è°ƒç”¨ AI ç”Ÿæˆæ‘˜è¦
            $asyncGemini = AIService::getAsyncGemini();
            $asyncGemini->chatStreamAsync(
                [
                    ['role' => 'user', 'content' => $conversationText . "\n\n" . $summarizePrompt]
                ],
                function ($text, $isThought) { /* å¿½ç•¥æµå¼è¾“å‡º */ },
                function ($summaryText) use ($chatId) {
                    // ä¿å­˜æ‘˜è¦å¹¶å‹ç¼©å†å²
                    if (!empty($summaryText)) {
                        CacheService::saveSummaryAndCompress($chatId, $summaryText);
                        echo "ğŸ“ å¯¹è¯ {$chatId} å·²è‡ªåŠ¨æ‘˜è¦\n";
                    }
                },
                function ($error) use ($chatId) {
                    echo "âŒ æ‘˜è¦ç”Ÿæˆå¤±è´¥ ({$chatId}): {$error}\n";
                },
                ['enableSearch' => false]
            );
        });
    });
}

// ===================================
// SSE æµå¼å¤„ç†
// ===================================

function sendSSE(TcpConnection $connection, string $event, string $data): void
{
    // SSE è§„èŒƒï¼šdata å­—æ®µä¸­çš„æ¢è¡Œç¬¦éœ€è¦åˆ†æˆå¤šè¡Œ data:
    // æˆ–è€…ç›´æ¥å°†æ¢è¡Œç¬¦æ›¿æ¢ä¸º \n å­—ç¬¦ä¸²ï¼ˆå‰ç«¯ä¼šå¤„ç†ï¼‰
    // è¿™é‡Œä½¿ç”¨åˆ†è¡Œæ–¹å¼
    $lines = explode("\n", $data);
    $message = "event: {$event}\n";
    foreach ($lines as $line) {
        $message .= "data: {$line}\n";
    }
    $message .= "\n";
    $connection->send($message);
}

function handleStreamAskAsync(TcpConnection $connection, Request $request): ?array
{
    $body = json_decode($request->rawBody(), true) ?? [];
    $question = $body['question'] ?? '';
    $chatId = $body['chat_id'] ?? '';
    $enableSearch = $body['search'] ?? true;
    $engine = $body['engine'] ?? 'google';
    $ragEnabled = $body['rag'] ?? true;
    $keywordWeight = floatval($body['keyword_weight'] ?? 0.5);
    $model = $body['model'] ?? 'gemini-2.5-flash';
    
    if (empty($question)) return ['error' => 'Missing question'];
    
    $headers = ['Content-Type' => 'text/event-stream', 'Cache-Control' => 'no-cache', 'Access-Control-Allow-Origin' => '*'];
    
    CacheService::getChatContext($chatId, function($context) use ($connection, $question, $chatId, $headers, $enableSearch, $engine, $ragEnabled, $keywordWeight, $model) {
        $connection->send(new Response(200, $headers, ''));
        
        $prompts = $GLOBALS['config']['prompts'];
        $libraryPrompts = $prompts['library'];
        $ragPrompts = $prompts['rag'];
        
        $bookTitle = 'æœªçŸ¥ä¹¦ç±';
        $bookAuthors = 'æœªçŸ¥ä½œè€…';
        
        if (defined('DEFAULT_BOOK_PATH') && file_exists(DEFAULT_BOOK_PATH)) {
            $metadata = \SmartBook\Parser\EpubParser::extractMetadata(DEFAULT_BOOK_PATH);
            if (!empty($metadata['title'])) $bookTitle = 'ã€Š' . $metadata['title'] . 'ã€‹';
            if (!empty($metadata['authors'])) $bookAuthors = $metadata['authors'];
        }
        
        // æ„å»ºæç¤ºè¯å¹¶è°ƒç”¨ AI çš„å‡½æ•°
        $doChat = function($ragContext, $ragSources) use (
            $connection, $question, $chatId, $enableSearch, $engine, $ragEnabled, $model,
            $context, $bookTitle, $bookAuthors, $prompts, $libraryPrompts, $ragPrompts
        ) {
            if ($ragEnabled && !empty($ragContext)) {
                $bookInfo = str_replace('{title}', $bookTitle, $ragPrompts['book_intro'] ?? 'I am discussing the book: {title}');
                if (!empty($bookAuthors)) {
                    $bookInfo .= str_replace('{authors}', $bookAuthors, $ragPrompts['author_template'] ?? ' by {authors}');
                }
                $systemPrompt = str_replace(['{book_info}', '{context}'], [$bookInfo, $ragContext], $ragPrompts['system'] ?? 'You are a book analysis assistant. {book_info}\n\nContext:\n{context}');
                sendSSE($connection, 'sources', json_encode($ragSources, JSON_UNESCAPED_UNICODE));
            } else {
                $bookInfo = $libraryPrompts['book_intro'] . str_replace(['{which}', '{title}', '{authors}'], ['', $bookTitle, $bookAuthors], $libraryPrompts['book_template']) . $libraryPrompts['separator'];
                $systemPrompt = $bookInfo . $libraryPrompts['markdown_instruction'] . ($libraryPrompts['unknown_single'] ?? '') . ' ' . str_replace('{language}', $prompts['language']['default'], $prompts['language']['instruction']);
                $sourceTexts = ['google' => 'AI é¢„è®­ç»ƒçŸ¥è¯† + Google Search', 'mcp' => 'AI é¢„è®­ç»ƒçŸ¥è¯† + MCP å·¥å…·', 'off' => 'AI é¢„è®­ç»ƒçŸ¥è¯†ï¼ˆæœç´¢å·²å…³é—­ï¼‰'];
                sendSSE($connection, 'sources', json_encode([['text' => $sourceTexts[$engine] ?? $sourceTexts['off'], 'score' => 100]], JSON_UNESCAPED_UNICODE));
            }
            
            if ($context['summary']) {
                $systemPrompt .= "\n\nã€å¯¹è¯å†å²æ‘˜è¦ã€‘\n" . $context['summary']['text'];
                sendSSE($connection, 'summary_used', json_encode(['rounds_summarized' => $context['summary']['rounds_summarized'], 'recent_messages' => count($context['messages']) / 2], JSON_UNESCAPED_UNICODE));
            }
            
            $messages = [['role' => 'system', 'content' => $systemPrompt]];
            foreach ($context['messages'] as $msg) {
                if (isset($msg['role']) && isset($msg['content'])) $messages[] = ['role' => $msg['role'], 'content' => $msg['content']];
            }
            $messages[] = ['role' => 'user', 'content' => $question];
            
            if ($chatId) CacheService::addToChatHistory($chatId, ['role' => 'user', 'content' => $question]);
            
            $asyncGemini = AIService::getAsyncGemini($model);
            $asyncGemini->chatStreamAsync(
                $messages,
                function ($text, $isThought) use ($connection) { if ($text) sendSSE($connection, $isThought ? 'thinking' : 'content', $text); },
                function ($fullAnswer, $usageMetadata = null, $usedModel = null) use ($connection, $chatId, $context, $model) {
                    if ($chatId) {
                        CacheService::addToChatHistory($chatId, ['role' => 'assistant', 'content' => $fullAnswer]);
                        triggerSummarizationIfNeeded($chatId, $context);
                    }
                    if ($usageMetadata) {
                        $costInfo = TokenCounter::calculateCost($usageMetadata, $usedModel ?? $model);
                        sendSSE($connection, 'usage', json_encode(['tokens' => $costInfo['tokens'], 'cost' => $costInfo['cost'], 'cost_formatted' => TokenCounter::formatCost($costInfo['cost']), 'currency' => $costInfo['currency'], 'model' => $usedModel ?? $model], JSON_UNESCAPED_UNICODE));
                    }
                    sendSSE($connection, 'done', '');
                    $connection->close();
                },
                function ($error) use ($connection) { sendSSE($connection, 'error', $error); $connection->close(); },
                ['enableSearch' => $enableSearch && $engine === 'google', 'enableTools' => $engine === 'mcp']
            );
        };
        
        // RAG æœç´¢é€»è¾‘ï¼šä½¿ç”¨æ–‡ä»¶å­˜å‚¨
        if ($ragEnabled && defined('DEFAULT_BOOK_CACHE') && file_exists(DEFAULT_BOOK_CACHE)) {
            try {
                $embedder = new EmbeddingClient(GEMINI_API_KEY);
                $queryEmbedding = $embedder->embedQuery($question);
                
                $ragContext = '';
                $ragSources = [];
                $chunkTemplate = $ragPrompts['chunk_template'] ?? "ã€Passage {index}ã€‘\n{text}\n";
                
                $vectorStore = new VectorStore(DEFAULT_BOOK_CACHE);
                $results = $vectorStore->hybridSearch($question, $queryEmbedding, 5, $keywordWeight);
                
                foreach ($results as $i => $result) {
                    $ragContext .= str_replace(['{index}', '{text}'], [$i + 1, $result['chunk']['text']], $chunkTemplate);
                    $ragContext .= "(Relevance: " . round($result['score'] * 100, 1) . "%)\n\n";
                    $ragSources[] = ['text' => mb_substr($result['chunk']['text'], 0, 200) . '...', 'score' => round($result['score'] * 100, 1)];
                }
                $doChat($ragContext, $ragSources);
            } catch (Exception $e) {
                $doChat('', []);
            }
        } else {
            $doChat('', []);
        }
    });
    
    return null;
}

function handleStreamChat(TcpConnection $connection, Request $request): ?array
{
    $body = json_decode($request->rawBody(), true) ?? [];
    $message = $body['message'] ?? '';
    $chatId = $body['chat_id'] ?? '';
    $enableSearch = $body['search'] ?? true;  // é»˜è®¤å¼€å¯æœç´¢
    $engine = $body['engine'] ?? 'google';    // é»˜è®¤ä½¿ç”¨ Google
    $model = $body['model'] ?? 'gemini-2.5-flash';  // æ¨¡å‹é€‰æ‹©
    
    if (empty($message)) return ['error' => 'Missing message'];
    
    $headers = ['Content-Type' => 'text/event-stream', 'Cache-Control' => 'no-cache', 'Access-Control-Allow-Origin' => '*'];
    
    // è·å–å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆåŒ…å«æ‘˜è¦ + æœ€è¿‘æ¶ˆæ¯ï¼‰
    CacheService::getChatContext($chatId, function($context) use ($connection, $message, $chatId, $headers, $enableSearch, $engine) {
        $connection->send(new Response(200, $headers, ''));
        
        $prompts = $GLOBALS['config']['prompts'];
        
        // é€šç”¨èŠå¤©ç³»ç»Ÿæç¤ºè¯
        $systemPrompt = $prompts['chat']['system'] ?? 'ä½ æ˜¯ä¸€ä¸ªå‹å–„ã€åšå­¦çš„ AI åŠ©æ‰‹ï¼Œæ“…é•¿å›ç­”å„ç§é—®é¢˜å¹¶æä¾›æœ‰ä»·å€¼çš„è§è§£ã€‚è¯·ç”¨ä¸­æ–‡å›ç­”ã€‚';
        
        // å‘é€ç³»ç»Ÿæç¤ºè¯ç»™å‰ç«¯æ˜¾ç¤º
        sendSSE($connection, 'system_prompt', $systemPrompt);
        
        // æ„å»ºæ¶ˆæ¯æ•°ç»„
        $messages = [['role' => 'system', 'content' => $systemPrompt]];
        
        // å¦‚æœæœ‰æ‘˜è¦ï¼Œæ·»åŠ ä¸ºç³»ç»Ÿæ¶ˆæ¯ï¼Œå¹¶é€šçŸ¥å‰ç«¯
        if ($context['summary']) {
            $messages[0]['content'] .= "\n\nã€å¯¹è¯å†å²æ‘˜è¦ã€‘\n" . $context['summary']['text'];
            sendSSE($connection, 'summary_used', json_encode([
                'rounds_summarized' => $context['summary']['rounds_summarized'],
                'recent_messages' => count($context['messages']) / 2
            ], JSON_UNESCAPED_UNICODE));
        }
        
        // æ·»åŠ æœ€è¿‘æ¶ˆæ¯
        foreach ($context['messages'] as $msg) {
            if (isset($msg['role']) && isset($msg['content'])) {
                $messages[] = ['role' => $msg['role'], 'content' => $msg['content']];
            }
        }
        $messages[] = ['role' => 'user', 'content' => $message];
        
        // ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
        if ($chatId) {
            CacheService::addToChatHistory($chatId, ['role' => 'user', 'content' => $message]);
        }
        
        $asyncGemini = AIService::getAsyncGemini();
        $asyncGemini->chatStreamAsync(
            $messages,
            function ($text, $isThought) use ($connection) { 
                if ($text) sendSSE($connection, $isThought ? 'thinking' : 'content', $text); 
            },
            function ($fullContent) use ($connection, $chatId, $context) { 
                // ä¿å­˜åŠ©æ‰‹å›å¤
                if ($chatId) {
                    CacheService::addToChatHistory($chatId, ['role' => 'assistant', 'content' => $fullContent]);
                    // æ£€æŸ¥æ˜¯å¦éœ€è¦è¿›è¡Œä¸Šä¸‹æ–‡å‹ç¼©
                    triggerSummarizationIfNeeded($chatId, $context);
                }
                sendSSE($connection, 'done', ''); 
                $connection->close(); 
            },
            function ($error) use ($connection) { 
                sendSSE($connection, 'error', $error); 
                $connection->close(); 
            },
            ['enableSearch' => $enableSearch && $engine === 'google', 'enableTools' => $engine === 'mcp']
        );
    });
    
    return null;
}

function handleStreamContinue(TcpConnection $connection, Request $request): ?array
{
    $body = json_decode($request->rawBody(), true) ?? [];
    $prompt = $body['prompt'] ?? '';
    
    $headers = ['Content-Type' => 'text/event-stream', 'Cache-Control' => 'no-cache', 'Access-Control-Allow-Origin' => '*'];
    $connection->send(new Response(200, $headers, ''));
    
    $systemPrompt = $GLOBALS['config']['prompts']['continue']['system'] ?? '';
    $userPrompt = $prompt ?: ($GLOBALS['config']['prompts']['continue']['default_prompt'] ?? '');
    
    $asyncGemini = AIService::getAsyncGemini();
    $asyncGemini->chatStreamAsync(
        [['role' => 'system', 'content' => $systemPrompt], ['role' => 'user', 'content' => $userPrompt]],
        function ($text, $isThought) use ($connection) { if (!$isThought && $text) sendSSE($connection, 'content', $text); },
        function ($fullContent) use ($connection) { sendSSE($connection, 'done', ''); $connection->close(); },
        function ($error) use ($connection) { sendSSE($connection, 'error', $error); $connection->close(); },
        ['enableSearch' => false]
    );
    return null;
}

// ===================================
// WebSocket æµå¼å¤„ç†
// ===================================

function streamAsk(TcpConnection $connection, array $request): void
{
    $question = $request['question'] ?? '';
    $topK = $request['top_k'] ?? 8;
    if (empty($question)) { $connection->send(json_encode(['error' => 'Missing question'])); return; }
    
    $embedder = new EmbeddingClient(GEMINI_API_KEY);
    $queryEmbedding = $embedder->embedQuery($question);
    
    $vectorStore = new VectorStore(DEFAULT_BOOK_CACHE);
    $results = $vectorStore->hybridSearch($question, $queryEmbedding, $topK, 0.6);
    
    $connection->send(json_encode(['type' => 'sources', 'sources' => array_map(fn($r) => ['text' => mb_substr($r['chunk']['text'], 0, 200) . '...', 'score' => round($r['score'] * 100, 1)], $results)]));
    
    $context = "";
    foreach ($results as $i => $result) $context .= "ã€ç‰‡æ®µ " . ($i + 1) . "ã€‘\n" . $result['chunk']['text'] . "\n\n";
    
    $gemini = AIService::getGemini();
    $gemini->chatStream(
        [['role' => 'system', 'content' => "ä½ æ˜¯ä¸€ä¸ªä¹¦ç±åˆ†æåŠ©æ‰‹ã€‚æ ¹æ®ä»¥ä¸‹å†…å®¹å›ç­”é—®é¢˜ï¼Œä½¿ç”¨ä¸­æ–‡ï¼š\n\n{$context}"], ['role' => 'user', 'content' => $question]],
        function ($text, $chunk, $isThought) use ($connection) { if (!$isThought && $text) $connection->send(json_encode(['type' => 'content', 'content' => $text])); },
        ['enableSearch' => false]
    );
    $connection->send(json_encode(['type' => 'done']));
}

function streamChat(TcpConnection $connection, array $request): void
{
    $messages = $request['messages'] ?? [];
    if (empty($messages)) { $connection->send(json_encode(['error' => 'Missing messages'])); return; }
    
    $gemini = AIService::getGemini();
    $gemini->chatStream(
        $messages,
        function ($text, $chunk, $isThought) use ($connection) { if (!$isThought && $text) $connection->send(json_encode(['type' => 'content', 'content' => $text])); },
        ['enableSearch' => false]
    );
    $connection->send(json_encode(['type' => 'done']));
}

function streamContinue(TcpConnection $connection, array $request): void
{
    $prompt = $request['prompt'] ?? '';
    $systemPrompt = $GLOBALS['config']['prompts']['continue']['system'] ?? '';
    $userPrompt = $prompt ?: ($GLOBALS['config']['prompts']['continue']['default_prompt'] ?? '');
    
    $gemini = AIService::getGemini();
    $gemini->chatStream(
        [['role' => 'system', 'content' => $systemPrompt], ['role' => 'user', 'content' => $userPrompt]],
        function ($text, $chunk, $isThought) use ($connection) { if (!$isThought && $text) $connection->send(json_encode(['type' => 'content', 'content' => $text])); },
        ['enableSearch' => false]
    );
    $connection->send(json_encode(['type' => 'done']));
}
