<?php
/**
 * èŠå¤©å¤„ç†å™¨
 */

namespace SmartBook\Http\Handlers;

use SmartBook\Logger;
use SmartBook\AI\AIService;
use SmartBook\AI\TokenCounter;
use SmartBook\AI\GeminiContextCache;
use SmartBook\Cache\CacheService;
use SmartBook\Http\Context;
use SmartBook\RAG\EmbeddingClient;
use SmartBook\RAG\VectorStore;
use Workerman\Protocols\Http\Response;

class ChatHandler
{   
    /**
     * æµå¼ä¹¦ç±é—®ç­”åŠ©æ‰‹ï¼ˆSSEï¼‰
     */
    public static function streamAskAsync(Context $ctx): ?array
    {
        $connection = $ctx->connection();
        $body = $ctx->jsonBody() ?? [];
        $question = $body['question'] ?? '';
        $chatId = $body['chat_id'] ?? '';
        $enableSearch = $body['search'] ?? true;
        $engine = $body['engine'] ?? 'google';
        $ragEnabled = $body['rag'] ?? true;
        $keywordWeight = floatval($body['keyword_weight'] ?? 0.5);
        $model = $body['model'] ?? 'gemini-2.5-flash';
        $assistantId = $body['assistant_id'] ?? 'ask';
        $bookId = $body['book_id'] ?? '';
        
        Logger::info("ðŸ¤– Assistant: {$assistantId} | ðŸŽ¯ Model: {$model}" . ($bookId ? " | ðŸ“š Book: {$bookId}" : ''));
        
        if (empty($question)) return ['error' => 'Missing question'];
        
        $headers = ['Content-Type' => 'text/event-stream', 'Cache-Control' => 'no-cache', 'Access-Control-Allow-Origin' => '*'];
        
        CacheService::getChatContext($chatId, function($context) use ($connection, $question, $chatId, $headers, $enableSearch, $engine, $ragEnabled, $keywordWeight, $model) {
            $connection->send(new Response(200, $headers, ''));
            
            $prompts = $GLOBALS['config']['prompts'];
            $libraryPrompts = $prompts['library'];
            $ragPrompts = $prompts['rag'];
            
            $bookTitle = 'æœªçŸ¥ä¹¦ç±';
            $bookAuthors = 'æœªçŸ¥ä½œè€…';
            
            $currentBookPath = ConfigHandler::getCurrentBookPath();
            if ($currentBookPath) {
                $ext = strtolower(pathinfo($currentBookPath, PATHINFO_EXTENSION));
                if ($ext === 'epub') {
                    $metadata = \SmartBook\Parser\EpubParser::extractMetadata($currentBookPath);
                    if (!empty($metadata['title'])) $bookTitle = 'ã€Š' . $metadata['title'] . 'ã€‹';
                    if (!empty($metadata['authors'])) $bookAuthors = $metadata['authors'];
                } else {
                    $bookTitle = 'ã€Š' . pathinfo($currentBookPath, PATHINFO_FILENAME) . 'ã€‹';
                }
            }
            
            $doChat = function($ragContext, $ragSources) use (
                $connection, $question, $chatId, $enableSearch, $engine, $ragEnabled, $model,
                $context, $bookTitle, $bookAuthors, $prompts, $libraryPrompts, $ragPrompts
            ) {
                if ($ragEnabled && !empty($ragContext)) {
                    $bookInfo = str_replace('{title}', $bookTitle, $ragPrompts['book_intro'] ?? 'I am discussing the book: {title}');
                    if (!empty($bookAuthors)) {
                        $bookInfo .= str_replace('{authors}', $bookAuthors, $ragPrompts['author_template'] ?? ' by {authors}');
                    }
                    $systemPrompt = str_replace(['{book_info}', '{context}'], [$bookInfo, $ragContext], $ragPrompts['system'] ?? 'You are a book analysis assistant. {book_info}\n\nContext:\n{context}');
                    StreamHelper::sendSSE($connection, 'sources', json_encode($ragSources, JSON_UNESCAPED_UNICODE));
                } else {
                    $bookInfo = $libraryPrompts['book_intro'] . str_replace(['{which}', '{title}', '{authors}'], ['', $bookTitle, $bookAuthors], $libraryPrompts['book_template']) . $libraryPrompts['separator'];
                    $systemPrompt = $bookInfo . $libraryPrompts['markdown_instruction'] . ($libraryPrompts['unknown_single'] ?? '') . ' ' . str_replace('{language}', $prompts['language']['default'], $prompts['language']['instruction']);
                    $sourceTexts = $prompts['source_texts'] ?? ['google' => 'AI é¢„è®­ç»ƒçŸ¥è¯† + Google Search', 'mcp' => 'AI é¢„è®­ç»ƒçŸ¥è¯† + MCP å·¥å…·', 'off' => 'AI é¢„è®­ç»ƒçŸ¥è¯†ï¼ˆæœç´¢å·²å…³é—­ï¼‰'];
                    StreamHelper::sendSSE($connection, 'sources', json_encode([['text' => $sourceTexts[$engine] ?? $sourceTexts['off'], 'score' => 100]], JSON_UNESCAPED_UNICODE));
                }
                
                if ($context['summary']) {
                    $historyLabel = $prompts['summarize']['history_label'] ?? 'ã€å¯¹è¯åŽ†å²æ‘˜è¦ã€‘';
                    $systemPrompt .= "\n\n{$historyLabel}\n" . $context['summary']['text'];
                    StreamHelper::sendSSE($connection, 'summary_used', json_encode(['rounds_summarized' => $context['summary']['rounds_summarized'], 'recent_messages' => count($context['messages']) / 2], JSON_UNESCAPED_UNICODE));
                }
                
                $messages = [['role' => 'system', 'content' => $systemPrompt]];
                foreach ($context['messages'] as $msg) {
                    if (isset($msg['role']) && isset($msg['content'])) $messages[] = ['role' => $msg['role'], 'content' => $msg['content']];
                }
                $messages[] = ['role' => 'user', 'content' => $question];
                
                if ($chatId) CacheService::addToChatHistory($chatId, ['role' => 'user', 'content' => $question]);
                
                $asyncGemini = AIService::getAsyncGemini($model);
                $isConnectionAlive = true;
                $requestId = $asyncGemini->chatStreamAsync(
                    $messages,
                    function ($text, $isThought) use ($connection, &$isConnectionAlive, &$requestId, $asyncGemini) {
                        if (!$isConnectionAlive) return;
                        if ($text) {
                            if (!StreamHelper::sendSSE($connection, $isThought ? 'thinking' : 'content', $text)) {
                                $isConnectionAlive = false;
                                if ($requestId) $asyncGemini->cancel($requestId);
                            }
                        }
                    },
                    function ($fullAnswer, $usageMetadata = null, $usedModel = null) use ($connection, $chatId, $context, $model, &$isConnectionAlive) {
                        if (!$isConnectionAlive) return;
                        if ($chatId) {
                            CacheService::addToChatHistory($chatId, ['role' => 'assistant', 'content' => $fullAnswer]);
                            self::triggerSummarizationIfNeeded($chatId, $context);
                        }
                        if ($usageMetadata) {
                            $costInfo = TokenCounter::calculateCost($usageMetadata, $usedModel ?? $model);
                            StreamHelper::sendSSE($connection, 'usage', json_encode(['tokens' => $costInfo['tokens'], 'cost' => $costInfo['cost'], 'cost_formatted' => TokenCounter::formatCost($costInfo['cost']), 'currency' => $costInfo['currency'], 'model' => $usedModel ?? $model], JSON_UNESCAPED_UNICODE));
                        }
                        StreamHelper::sendSSE($connection, 'done', '');
                        $connection->close();
                    },
                    function ($error) use ($connection, &$isConnectionAlive) {
                        if (!$isConnectionAlive) return;
                        StreamHelper::sendSSE($connection, 'error', $error);
                        $connection->close();
                    },
                    ['enableSearch' => $enableSearch && $engine === 'google', 'enableTools' => $engine === 'mcp']
                );
            };
            
            $currentCache = ConfigHandler::getCurrentBookCache();
            if ($ragEnabled && $currentCache) {
                try {
                    $embedder = new EmbeddingClient(GEMINI_API_KEY);
                    $queryEmbedding = $embedder->embedQuery($question);
                    
                    $ragContext = '';
                    $ragSources = [];
                    $chunkTemplate = $ragPrompts['chunk_template'] ?? "ã€Passage {index}ã€‘\n{text}\n";
                    
                    $vectorStore = new VectorStore($currentCache);
                    $results = $vectorStore->hybridSearch($question, $queryEmbedding, 5, $keywordWeight);
                    
                    foreach ($results as $i => $result) {
                        $ragContext .= str_replace(['{index}', '{text}'], [$i + 1, $result['chunk']['text']], $chunkTemplate);
                        $ragContext .= "(Relevance: " . round($result['score'] * 100, 1) . "%)\n\n";
                        $ragSources[] = ['text' => mb_substr($result['chunk']['text'], 0, 200) . '...', 'score' => round($result['score'] * 100, 1)];
                    }
                    $doChat($ragContext, $ragSources);
                } catch (\Exception $e) {
                    $doChat('', []);
                }
            } else {
                $doChat('', []);
            }
        });
        
        return null;
    }
    
    /**
     * æµå¼é€šç”¨èŠå¤©ï¼ˆSSEï¼‰
     */
    public static function streamChat(Context $ctx): ?array
    {
        $connection = $ctx->connection();
        $body = $ctx->jsonBody() ?? [];
        $message = $body['message'] ?? '';
        $chatId = $body['chat_id'] ?? '';
        $enableSearch = $body['search'] ?? true;
        $engine = $body['engine'] ?? 'google';
        $model = $body['model'] ?? 'gemini-2.5-flash';
        $assistantId = $body['assistant_id'] ?? 'chat';  // æ–°å¢žï¼šèŽ·å–åŠ©æ‰‹ ID
        
        Logger::info("ðŸ¤– Assistant: {$assistantId} | ðŸŽ¯ Model: {$model}");
        
        $clientSummary = $body['summary'] ?? null;
        $clientHistory = $body['history'] ?? null;
        
        if (empty($message)) return ['error' => 'Missing message'];
        
        $headers = ['Content-Type' => 'text/event-stream', 'Cache-Control' => 'no-cache', 'Access-Control-Allow-Origin' => '*'];
        
        if ($clientSummary !== null || $clientHistory !== null) {
            $connection->send(new Response(200, $headers, ''));
            
            $prompts = $GLOBALS['config']['prompts'];
            $sourceTexts = $prompts['source_texts'] ?? ['google' => 'AI é¢„è®­ç»ƒçŸ¥è¯† + Google Search', 'mcp' => 'AI é¢„è®­ç»ƒçŸ¥è¯† + MCP å·¥å…·', 'off' => 'AI é¢„è®­ç»ƒçŸ¥è¯†ï¼ˆæœç´¢å·²å…³é—­ï¼‰'];
            StreamHelper::sendSSE($connection, 'sources', json_encode([['text' => $sourceTexts[$engine] ?? $sourceTexts['off'], 'score' => 100]], JSON_UNESCAPED_UNICODE));
            
            // æ ¹æ®åŠ©æ‰‹ç±»åž‹èŽ·å–ç³»ç»Ÿæç¤ºè¯
            $systemPrompt = self::getSystemPromptForAssistant($assistantId, $prompts);
            $messages = [['role' => 'system', 'content' => $systemPrompt]];
            
            if ($clientSummary) {
                $historyLabel = $prompts['summarize']['history_label'] ?? 'ã€å¯¹è¯åŽ†å²æ‘˜è¦ã€‘';
                $messages[0]['content'] .= "\n\n{$historyLabel}\n" . $clientSummary;
                StreamHelper::sendSSE($connection, 'summary_used', json_encode(['source' => 'ios_client', 'has_summary' => true], JSON_UNESCAPED_UNICODE));
            }
            
            if (is_array($clientHistory)) {
                foreach ($clientHistory as $msg) {
                    if (isset($msg['role']) && isset($msg['content'])) {
                        $messages[] = ['role' => $msg['role'], 'content' => $msg['content']];
                    }
                }
            }
            
            $messages[] = ['role' => 'user', 'content' => $message];
            
            Logger::info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
            Logger::info("ðŸ“‹ æäº¤ç»™ Gemini çš„å®Œæ•´ Prompt");
            Logger::info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
            Logger::info("ðŸ¤– æ¨¡åž‹: {$model}");
            Logger::info("ðŸ“Š æ¶ˆæ¯æ•°é‡: " . count($messages));
            Logger::info("");
            
            foreach ($messages as $index => $msg) {
                $role = match($msg['role']) {
                    'system' => 'âš™ï¸ System',
                    'user' => 'ðŸ‘¤ User',
                    'assistant' => 'ðŸ¤– Assistant',
                    default => 'â“ Unknown'
                };
                
                $content = $msg['content'];
                $length = mb_strlen($content);
                
                Logger::info("[æ¶ˆæ¯ " . ($index + 1) . "] {$role} ({$length} å­—ç¬¦)");
                Logger::info("---");
                Logger::info($content);
                Logger::info("---");
                Logger::info("");
            }
            
            $totalLength = array_reduce($messages, fn($sum, $msg) => $sum + mb_strlen($msg['content']), 0);
            $estimatedTokens = intval($totalLength / 3);
            
            Logger::info("ðŸ“Š ç»Ÿè®¡ä¿¡æ¯:");
            Logger::info("  â€¢ æ€»æ¶ˆæ¯æ•°: " . count($messages));
            Logger::info("  â€¢ æ€»å­—ç¬¦æ•°: {$totalLength}");
            Logger::info("  â€¢ ä¼°ç®— Tokens: ~{$estimatedTokens}");
            Logger::info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
            
            $asyncGemini = AIService::getAsyncGemini($model);
            $isConnectionAlive = true;
            $requestId = $asyncGemini->chatStreamAsync(
                $messages,
                function ($text, $isThought) use ($connection, &$isConnectionAlive, &$requestId, $asyncGemini) {
                    if (!$isConnectionAlive) return;
                    if ($text) {
                        if (!StreamHelper::sendSSE($connection, $isThought ? 'thinking' : 'content', $text)) {
                            $isConnectionAlive = false;
                            if ($requestId) $asyncGemini->cancel($requestId);
                        }
                    }
                },
                function ($fullContent, $usageMetadata = null, $usedModel = null) use ($connection, $model, &$isConnectionAlive) {
                    if (!$isConnectionAlive) return;
                    if ($usageMetadata) {
                        $costInfo = TokenCounter::calculateCost($usageMetadata, $usedModel ?? $model);
                        StreamHelper::sendSSE($connection, 'usage', json_encode([
                            'tokens' => $costInfo['tokens'], 
                            'cost' => $costInfo['cost'], 
                            'cost_formatted' => TokenCounter::formatCost($costInfo['cost']), 
                            'currency' => $costInfo['currency'], 
                            'model' => $usedModel ?? $model
                        ], JSON_UNESCAPED_UNICODE));
                    }
                    StreamHelper::sendSSE($connection, 'done', ''); 
                    $connection->close(); 
                },
                function ($error) use ($connection, &$isConnectionAlive) {
                    if (!$isConnectionAlive) return;
                    StreamHelper::sendSSE($connection, 'error', $error); 
                    $connection->close(); 
                },
                ['enableSearch' => $enableSearch && $engine === 'google', 'enableTools' => $engine === 'mcp']
            );
            
            return null;
        }
        
        CacheService::getChatContext($chatId, function($context) use ($connection, $message, $chatId, $headers, $enableSearch, $engine, $model, $assistantId) {
            $connection->send(new Response(200, $headers, ''));
            
            $prompts = $GLOBALS['config']['prompts'];
            $sourceTexts = $prompts['source_texts'] ?? ['google' => 'AI é¢„è®­ç»ƒçŸ¥è¯† + Google Search', 'mcp' => 'AI é¢„è®­ç»ƒçŸ¥è¯† + MCP å·¥å…·', 'off' => 'AI é¢„è®­ç»ƒçŸ¥è¯†ï¼ˆæœç´¢å·²å…³é—­ï¼‰'];
            StreamHelper::sendSSE($connection, 'sources', json_encode([['text' => $sourceTexts[$engine] ?? $sourceTexts['off'], 'score' => 100]], JSON_UNESCAPED_UNICODE));
            
            // æ ¹æ®åŠ©æ‰‹ç±»åž‹èŽ·å–ç³»ç»Ÿæç¤ºè¯
            $systemPrompt = self::getSystemPromptForAssistant($assistantId, $prompts);
            $messages = [['role' => 'system', 'content' => $systemPrompt]];
            
            if ($context['summary']) {
                $historyLabel = $prompts['summarize']['history_label'] ?? 'ã€å¯¹è¯åŽ†å²æ‘˜è¦ã€‘';
                $messages[0]['content'] .= "\n\n{$historyLabel}\n" . $context['summary']['text'];
                StreamHelper::sendSSE($connection, 'summary_used', json_encode([
                    'rounds_summarized' => $context['summary']['rounds_summarized'],
                    'recent_messages' => count($context['messages']) / 2
                ], JSON_UNESCAPED_UNICODE));
            }
            
            foreach ($context['messages'] as $msg) {
                if (isset($msg['role']) && isset($msg['content'])) {
                    $messages[] = ['role' => $msg['role'], 'content' => $msg['content']];
                }
            }
            $messages[] = ['role' => 'user', 'content' => $message];
            
            if ($chatId) {
                CacheService::addToChatHistory($chatId, ['role' => 'user', 'content' => $message]);
            }
            
            $asyncGemini = AIService::getAsyncGemini($model);
            $isConnectionAlive = true;
            $requestId = $asyncGemini->chatStreamAsync(
                $messages,
                function ($text, $isThought) use ($connection, &$isConnectionAlive, &$requestId, $asyncGemini) {
                    if (!$isConnectionAlive) return;
                    if ($text) {
                        if (!StreamHelper::sendSSE($connection, $isThought ? 'thinking' : 'content', $text)) {
                            $isConnectionAlive = false;
                            if ($requestId) $asyncGemini->cancel($requestId);
                        }
                    }
                },
                function ($fullContent, $usageMetadata = null, $usedModel = null) use ($connection, $chatId, $context, $model, &$isConnectionAlive) {
                    if (!$isConnectionAlive) return;
                    if ($chatId) {
                        CacheService::addToChatHistory($chatId, ['role' => 'assistant', 'content' => $fullContent]);
                        self::triggerSummarizationIfNeeded($chatId, $context);
                    }
                    if ($usageMetadata) {
                        $costInfo = TokenCounter::calculateCost($usageMetadata, $usedModel ?? $model);
                        StreamHelper::sendSSE($connection, 'usage', json_encode([
                            'tokens' => $costInfo['tokens'], 
                            'cost' => $costInfo['cost'], 
                            'cost_formatted' => TokenCounter::formatCost($costInfo['cost']), 
                            'currency' => $costInfo['currency'], 
                            'model' => $usedModel ?? $model
                        ], JSON_UNESCAPED_UNICODE));
                    }
                    StreamHelper::sendSSE($connection, 'done', ''); 
                    $connection->close(); 
                },
                function ($error) use ($connection, &$isConnectionAlive) {
                    if (!$isConnectionAlive) return;
                    StreamHelper::sendSSE($connection, 'error', $error); 
                    $connection->close(); 
                },
                ['enableSearch' => $enableSearch && $engine === 'google', 'enableTools' => $engine === 'mcp']
            );
        });
        
        return null;
    }
    
    /**
     * æµå¼ç»­å†™å°è¯´ï¼ˆSSEï¼‰
     */
    public static function streamContinue(Context $ctx): ?array
    {
        $connection = $ctx->connection();
        $body = $ctx->jsonBody() ?? [];
        $prompt = $body['prompt'] ?? '';
        $enableSearch = $body['search'] ?? false;
        $engine = $body['engine'] ?? 'off';
        $ragEnabled = $body['rag'] ?? false;
        $keywordWeight = floatval($body['keyword_weight'] ?? 0.5);
        $model = $body['model'] ?? 'gemini-2.5-flash';
        
        $headers = ['Content-Type' => 'text/event-stream', 'Cache-Control' => 'no-cache', 'Access-Control-Allow-Origin' => '*'];
        $connection->send(new Response(200, $headers, ''));
        
        $prompts = $GLOBALS['config']['prompts'];
        $ragPrompts = $prompts['rag'];
        
        $bookTitle = 'å½“å‰ä¹¦ç±';
        $currentBookPath = ConfigHandler::getCurrentBookPath();
        if ($currentBookPath) {
            $ext = strtolower(pathinfo($currentBookPath, PATHINFO_EXTENSION));
            if ($ext === 'epub') {
                $metadata = \SmartBook\Parser\EpubParser::extractMetadata($currentBookPath);
                if (!empty($metadata['title'])) $bookTitle = 'ã€Š' . $metadata['title'] . 'ã€‹';
            } else {
                $bookTitle = 'ã€Š' . pathinfo($currentBookPath, PATHINFO_FILENAME) . 'ã€‹';
            }
        }
        
        $baseSystemPrompt = str_replace('{title}', $bookTitle, $prompts['continue']['system'] ?? '');
        $userPrompt = $prompt ?: str_replace('{title}', $bookTitle, $prompts['continue']['default_prompt'] ?? '');
        
        $continuePrompts = $prompts['continue'];
        $doChat = function($ragContext, $ragSources) use (
            $connection, $baseSystemPrompt, $userPrompt, $enableSearch, $engine, $model, $prompts, $ragEnabled, $continuePrompts
        ) {
            $systemPrompt = $baseSystemPrompt;
            
            if ($ragEnabled && !empty($ragContext)) {
                $ragInstruction = $continuePrompts['rag_instruction'] ?? '';
                $systemPrompt .= str_replace('{context}', $ragContext, $ragInstruction);
                StreamHelper::sendSSE($connection, 'sources', json_encode($ragSources, JSON_UNESCAPED_UNICODE));
            } else {
                $sourceTexts = $prompts['source_texts'] ?? ['google' => 'AI é¢„è®­ç»ƒçŸ¥è¯† + Google Search', 'mcp' => 'AI é¢„è®­ç»ƒçŸ¥è¯† + MCP å·¥å…·', 'off' => 'AI é¢„è®­ç»ƒçŸ¥è¯†ï¼ˆæœç´¢å·²å…³é—­ï¼‰'];
                StreamHelper::sendSSE($connection, 'sources', json_encode([['text' => $sourceTexts[$engine] ?? $sourceTexts['off'], 'score' => 100]], JSON_UNESCAPED_UNICODE));
            }
            
            $asyncGemini = AIService::getAsyncGemini($model);
            $isConnectionAlive = true;
            $requestId = $asyncGemini->chatStreamAsync(
                [['role' => 'system', 'content' => $systemPrompt], ['role' => 'user', 'content' => $userPrompt]],
                function ($text, $isThought) use ($connection, &$isConnectionAlive, &$requestId, $asyncGemini) {
                    if (!$isConnectionAlive) return;
                    if (!$isThought && $text) {
                        if (!StreamHelper::sendSSE($connection, 'content', $text)) {
                            $isConnectionAlive = false;
                            if ($requestId) $asyncGemini->cancel($requestId);
                        }
                    }
                },
                function ($fullContent, $usageMetadata = null, $usedModel = null) use ($connection, $model, &$isConnectionAlive) {
                    if (!$isConnectionAlive) return;
                    if ($usageMetadata) {
                        $costInfo = TokenCounter::calculateCost($usageMetadata, $usedModel ?? $model);
                        StreamHelper::sendSSE($connection, 'usage', json_encode([
                            'tokens' => $costInfo['tokens'], 
                            'cost' => $costInfo['cost'], 
                            'cost_formatted' => TokenCounter::formatCost($costInfo['cost']), 
                            'currency' => $costInfo['currency'], 
                            'model' => $usedModel ?? $model
                        ], JSON_UNESCAPED_UNICODE));
                    }
                    StreamHelper::sendSSE($connection, 'done', ''); 
                    $connection->close(); 
                },
                function ($error) use ($connection, &$isConnectionAlive) {
                    if (!$isConnectionAlive) return;
                    StreamHelper::sendSSE($connection, 'error', $error);
                    $connection->close();
                },
                ['enableSearch' => $enableSearch && $engine === 'google', 'enableTools' => $engine === 'mcp']
            );
        };
        
        $currentCache = ConfigHandler::getCurrentBookCache();
        if ($ragEnabled && $currentCache) {
            try {
                $embedder = new EmbeddingClient(GEMINI_API_KEY);
                $queryEmbedding = $embedder->embedQuery($userPrompt);
                
                $ragContext = '';
                $ragSources = [];
                $chunkTemplate = $ragPrompts['chunk_template'] ?? "ã€Passage {index}ã€‘\n{text}\n";
                
                $vectorStore = new VectorStore($currentCache);
                $results = $vectorStore->hybridSearch($userPrompt, $queryEmbedding, 5, $keywordWeight);
                
                foreach ($results as $i => $result) {
                    $ragContext .= str_replace(['{index}', '{text}'], [$i + 1, $result['chunk']['text']], $chunkTemplate);
                    $ragContext .= "(Relevance: " . round($result['score'] * 100, 1) . "%)\n\n";
                    $ragSources[] = ['text' => mb_substr($result['chunk']['text'], 0, 200) . '...', 'score' => round($result['score'] * 100, 1)];
                }
                $doChat($ragContext, $ragSources);
            } catch (\Exception $e) {
                $doChat('', []);
            }
        } else {
            $doChat('', []);
        }
        
        return null;
    }
    
    /**
     * æ ¹æ®åŠ©æ‰‹ ID èŽ·å–ç³»ç»Ÿæç¤ºè¯
     */
    private static function getSystemPromptForAssistant(string $assistantId, array $prompts): string
    {
        // èŽ·å–åŠ©æ‰‹é…ç½®åˆ—è¡¨
        $assistants = ConfigHandler::getAssistants();
        $assistantsList = $assistants['list'] ?? [];
        
        // æŸ¥æ‰¾åŒ¹é…çš„åŠ©æ‰‹
        foreach ($assistantsList as $assistant) {
            if ($assistant['id'] === $assistantId) {
                return $assistant['system_prompt'] ?? '';
            }
        }
        
        // å¦‚æžœæ²¡æ‰¾åˆ°ï¼Œè¿”å›žé€šç”¨èŠå¤©çš„ç³»ç»Ÿæç¤ºè¯
        return $prompts['chat']['system_prompt'] ?? '';
    }
    
    /**
     * æ£€æŸ¥å¹¶è§¦å‘ä¸Šä¸‹æ–‡æ‘˜è¦
     */
    public static function triggerSummarizationIfNeeded(string $chatId, array $context): void
    {
        CacheService::needsSummarization($chatId, function($needsSummary) use ($chatId, $context) {
            if (!$needsSummary) return;
            
            CacheService::getChatHistory($chatId, function($history) use ($chatId, $context) {
                if (empty($history)) return;
                
                $prompts = $GLOBALS['config']['prompts'];
                $summarizeConfig = $prompts['summarize'] ?? [];
                $roleNames = $prompts['role_names'] ?? ['user' => 'ç”¨æˆ·', 'assistant' => 'AI'];
                
                $conversationText = "";
                if ($context['summary']) {
                    $prevLabel = $summarizeConfig['previous_summary_label'] ?? 'ã€ä¹‹å‰çš„æ‘˜è¦ã€‘';
                    $newLabel = $summarizeConfig['new_conversation_label'] ?? 'ã€æ–°å¯¹è¯ã€‘';
                    $conversationText .= "{$prevLabel}\n" . $context['summary']['text'] . "\n\n{$newLabel}\n";
                }
                foreach ($history as $msg) {
                    $role = $roleNames[$msg['role']] ?? ($msg['role'] === 'user' ? 'ç”¨æˆ·' : 'AI');
                    $conversationText .= "{$role}: {$msg['content']}\n\n";
                }
                
                $summarizePrompt = CacheService::getSummarizePrompt();
                
                $asyncGemini = AIService::getAsyncGemini();
                $asyncGemini->chatStreamAsync(
                    [
                        ['role' => 'user', 'content' => $conversationText . "\n\n" . $summarizePrompt]
                    ],
                    function ($text, $isThought) { },
                    function ($summaryText) use ($chatId) {
                        if (!empty($summaryText)) {
                            CacheService::saveSummaryAndCompress($chatId, $summaryText);
                            Logger::info("å¯¹è¯ {$chatId} å·²è‡ªåŠ¨æ‘˜è¦");
                        }
                    },
                    function ($error) use ($chatId) {
                        Logger::error("æ‘˜è¦ç”Ÿæˆå¤±è´¥ ({$chatId}): {$error}");
                    },
                    ['enableSearch' => false]
                );
            });
        });
    }
    
    /**
     * åŸºäºŽ Context Cache çš„ä¹¦ç±é—®ç­”ï¼ˆæ— éœ€ RAG å’Œ embeddingï¼‰
     */
    public static function streamAskWithCache(Context $ctx): ?array
    {
        $connection = $ctx->connection();
        $body = $ctx->jsonBody() ?? [];
        $question = $body['question'] ?? '';
        $bookId = $body['book_id'] ?? '';
        $model = $body['model'] ?? 'gemini-2.0-flash';
        $assistantId = $body['assistant_id'] ?? 'ask';
        
        Logger::info("ðŸ¤– Assistant: {$assistantId} | ðŸŽ¯ Model: {$model} | ðŸ“š Book: {$bookId} (Context Cache)");
        
        if (empty($question)) {
            return ['error' => 'Missing question'];
        }
        
        if (empty($bookId)) {
            return ['error' => 'Missing book_id'];
        }
        
        $headers = [
            'Content-Type' => 'text/event-stream',
            'Cache-Control' => 'no-cache',
            'Access-Control-Allow-Origin' => '*'
        ];
        $connection->send(new Response(200, $headers, ''));
        
        try {
            $cacheClient = new GeminiContextCache(GEMINI_API_KEY, $model);
            $bookCache = $cacheClient->getBookCache($bookId);
            
            if (!$bookCache) {
                // åˆ›å»º Context Cache
                StreamHelper::sendSSE($connection, 'sources', json_encode([
                    ['text' => "æ­£åœ¨ä¸ºã€Š{$bookId}ã€‹åˆ›å»º Context Cache...", 'score' => 0]
                ], JSON_UNESCAPED_UNICODE));
                
                $booksDir = dirname(__DIR__, 3) . '/books';
                $bookPath = $booksDir . '/' . $bookId;
                
                if (!file_exists($bookPath)) {
                    StreamHelper::sendSSE($connection, 'error', "ä¹¦ç±æ–‡ä»¶ä¸å­˜åœ¨: {$bookId}");
                    $connection->close();
                    return null;
                }
                
                $ext = strtolower(pathinfo($bookId, PATHINFO_EXTENSION));
                if ($ext === 'epub') {
                    $content = \SmartBook\Parser\EpubParser::extractText($bookPath);
                } else {
                    $content = file_get_contents($bookPath);
                }
                
                if (empty($content)) {
                    StreamHelper::sendSSE($connection, 'error', "æ— æ³•æå–ä¹¦ç±å†…å®¹");
                    $connection->close();
                    return null;
                }
                
                $createResult = $cacheClient->createForBook($bookId, $content, 7200);
                
                if (!$createResult['success']) {
                    StreamHelper::sendSSE($connection, 'error', "åˆ›å»ºç¼“å­˜å¤±è´¥: " . ($createResult['error'] ?? 'æœªçŸ¥é”™è¯¯'));
                    $connection->close();
                    return null;
                }
                
                $bookCache = $cacheClient->getBookCache($bookId);
                
                if (!$bookCache) {
                    StreamHelper::sendSSE($connection, 'error', "åˆ›å»ºç¼“å­˜åŽä»æ— æ³•èŽ·å–");
                    $connection->close();
                    return null;
                }
                
                StreamHelper::sendSSE($connection, 'sources', json_encode([
                    ['text' => "âœ… Context Cache åˆ›å»ºæˆåŠŸï¼", 'score' => 100]
                ], JSON_UNESCAPED_UNICODE));
            }
            
            $cacheModel = str_replace('models/', '', $bookCache['model'] ?? '');
            if ($cacheModel !== $model) {
                $errorMsg = "âš ï¸ æ¨¡åž‹ä¸åŒ¹é…ï¼\n\n" .
                    "â€¢ å½“å‰é€‰æ‹©: {$model}\n" .
                    "â€¢ ç¼“å­˜è¦æ±‚: {$cacheModel}\n\n" .
                    "è¯·åˆ‡æ¢åˆ° {$cacheModel} æ¨¡åž‹åŽé‡è¯•ã€‚";
                StreamHelper::sendSSE($connection, 'error', $errorMsg);
                $connection->close();
                return null;
            }
            
            $tokenCount = $bookCache['usageMetadata']['totalTokenCount'] ?? 0;
            StreamHelper::sendSSE($connection, 'sources', json_encode([
                ['text' => "Context Cacheï¼ˆ{$tokenCount} tokensï¼Œæ— éœ€ embeddingï¼‰", 'score' => 100]
            ], JSON_UNESCAPED_UNICODE));
            
            // ä½¿ç”¨ Context Cache ç›´æŽ¥é—®ç­”
            $asyncGemini = AIService::getAsyncGemini($cacheModel);
            $isConnectionAlive = true;
            
            $asyncGemini->chatStreamAsyncWithCache(
                $bookCache['name'],
                [['role' => 'user', 'content' => $question]],
                function ($text, $isThought) use ($connection, &$isConnectionAlive) {
                    if (!$isConnectionAlive) return;
                    if ($text) {
                        if (!StreamHelper::sendSSE($connection, $isThought ? 'thinking' : 'content', $text)) {
                            $isConnectionAlive = false;
                        }
                    }
                },
                function ($fullAnswer, $usageMetadata = null, $usedModel = null) use ($connection, $cacheModel, &$isConnectionAlive) {
                    if (!$isConnectionAlive) return;
                    if ($usageMetadata) {
                        $costInfo = TokenCounter::calculateCost($usageMetadata, $usedModel ?? $cacheModel);
                        StreamHelper::sendSSE($connection, 'usage', json_encode([
                            'tokens' => $costInfo['tokens'],
                            'cost' => $costInfo['cost'],
                            'cost_formatted' => TokenCounter::formatCost($costInfo['cost']),
                            'currency' => $costInfo['currency'],
                            'model' => $usedModel ?? $cacheModel
                        ], JSON_UNESCAPED_UNICODE));
                    }
                    StreamHelper::sendSSE($connection, 'done', '');
                    $connection->close();
                },
                function ($error) use ($connection, &$isConnectionAlive) {
                    if (!$isConnectionAlive) return;
                    StreamHelper::sendSSE($connection, 'error', $error);
                    $connection->close();
                }
            );
            
        } catch (\Exception $e) {
            StreamHelper::sendSSE($connection, 'error', $e->getMessage());
            $connection->close();
        }
        
        return null;
    }
}
